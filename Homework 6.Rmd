---
title: "Homework 6"
author: "Jeanette Shekelle"
date: "11/27/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(purrr)
```


### Introduction:

The purpose of this document is to practice fitting linear models for P8105 Homework 6. 


## Problem 1


#### Reading in the data:

```{r}
homicide_data = read_csv(file = "./data/homicide_data.csv")
```


Cleaning the data:


```{r}
homicide_data_clean = 
  homicide_data %>% 
  janitor::clean_names() %>% 
  mutate(city_state = paste(city, state, sep = ', '),
         solved = as.factor(ifelse(disposition == 'Closed by arrest', 'solved', 'unsolved'))) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) %>% 
  mutate(victim_race = as.factor(ifelse(victim_race == 'White', 'white', 'non-white' )),
         victim_age = as.numeric(victim_age),
         victim_sex = as.factor(victim_sex),
         victim_race = fct_relevel(victim_race, "white"))
```



Fitting logistic regression using glm:

```{r}
fit_logistic = 
  homicide_data_clean%>% 
  filter(city_state == "Baltimore, MD") %>%
  glm(solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         low_OR = exp(estimate * 1.96 - std.error),
         high_OR = exp(estimate * 1.96 + std.error)) %>%
  select(OR, low_OR, high_OR, p.value) %>% 
  knitr::kable(digits = 3)
```


## Problem 2

Loading birthweight data:

```{r}
birthweight_data = read_csv(file = "./data/birthweight.csv")
```


Cleaning the data for regression analysis:

```{r}
birthweight_data_clean = 
  birthweight_data %>% 
  janitor::clean_names() %>% 
  mutate(malform = as.factor(malform),
         babysex = as.factor(babysex),
         mrace = as.factor(mrace),
         pnumlbw = as.numeric(pnumlbw),
         pnumsga = as.numeric(pnumsga))
```


Making a model for birthweight: 

I am choosing to focus on the exposure of mother's pre-pregnancy BMI and the outcome of birthweight. There is evidence that suggests that the higher the mother's pre-pregnancy BMI, the higher the baby's birthweight will be. (Source: https://www.ncbi.nlm.nih.gov/pubmed/25863988 )


```{r}
birthweight_fit = lm(bwt ~ ppbmi, data = birthweight_data_clean) %>% 
  broom::tidy()
   
```


Plot of model residuals against fitted values:

```{r}
birthweight_data_clean %>% 
  modelr::add_predictions(birthweight_fit) %>% 
  modelr::add_residuals(birthweight_fit) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
```

This plot shows me that I chose a bad model. It is very skewed and has lots of uncontrolled confounding. 


Comparing my model to two others:

1) One using length at birth and gestational age as predictors (main effects only)


```{r}
birthweight_fit_1 = lm(bwt ~ blength + gaweeks, data = birthweight_data_clean) %>% 
  broom::tidy() 
```


2) One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
birthweight_fit_2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + 
                         blength*babysex + bhead*blength*babysex, data = birthweight_data_clean) %>% 
  broom::tidy()
```



Making this comparison in terms of the cross-validated prediction error:


```{r}
cv_df = crossv_mc(birthweight_data_clean, 100)
 
cv_df = 
  cv_df %>% 
  mutate(birthweight_fit = map(train, ~lm(bwt ~ mrace + blength + momage, data = .x)),
         birthweight_fit_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         birthweight_fit_2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_birthweight_fit = map2_dbl(birthweight_fit, test, ~rmse(model = .x, data = .y)),
         rmse_birthweight_fit_1 = map2_dbl(birthweight_fit_1, test, ~rmse(model = .x, data = .y)),
         rmse_birthweight_fit_2 = map2_dbl(birthweight_fit_2, test, ~rmse(model = .x, data = .y)))
```


Plotting:

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() 
```

Here I can see the Root Mean Square Errors for the 3 models. My model is very similar to the middle model. Both my model and the middle model have an RMSE of about 330. The right model has a RMSE of ~285. This is much lower than the first two models, so it is the best to use. This makes sense since it had the most terms added to the model statement, so it was accounting for many other variables. 